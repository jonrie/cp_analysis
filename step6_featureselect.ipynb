{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pycytominer\n",
    "\n",
    "os.chdir('./output/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Processing Steps (https://github.com/cytodata/single-cell-classifier/blob/9d43dfb15bae9dd66a3e9fce502c6cb878b31d08/2.process-data/scripts/nbconverted/1.process-ebimage-features.py)\n",
    "\n",
    "# https://pycytominer.readthedocs.io/en/latest/pycytominer.html\n",
    "\n",
    "# 1. Remove features that have high missingness\n",
    "#   * Remove features that have a proportion of missing values greater than 1%\n",
    "\n",
    "# 2. Remove redundant features (high correlation)\n",
    "#   * Remove features that have correlations with other features greater than 0.95 Pearson correlation\n",
    "#   * Retain the feature with the lowest correlation in each highly correlated block of features\n",
    "\n",
    "# 3. Remove low variance features\n",
    "#   * Remove features with a ratio of second most common value / most common less than 1%\n",
    "#     * Removes features that have a common and high outlier\n",
    "#   * Remove features with a ratio of second max count / max count less than 0.1%\n",
    "#     * Removes features that have a very high number of redundant values\n",
    "\n",
    "# 4. Apply robust normalization\n",
    "#   * subtract median and divide by IQR\n",
    "#   * robust to outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For fingerprint generation, all features can be used (Gustafsdottir et al., 2013)\n",
    "# or an optional feature selection step may be included in the analysis pipeline to exclude features that carry no information (median absolute deviation [MAD] close to 0) or are highly redundant (Pearson correlation >0.9 or >0.95) \n",
    "#(Hughes et al., 2020; Warchal et al., 2020). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blocklist_features(df):\n",
    "    cleaned_df = pycytominer.feature_select(\n",
    "        profiles=df,\n",
    "        operation=\"blocklist\"\n",
    "    )\n",
    "    num_removed = df.shape[1] - cleaned_df.shape[1]\n",
    "    print(f\"A total of {num_removed} features are removed from a total of 55 blocklisted features. {cleaned_df.shape[1]} features remaining\")\n",
    "    return cleaned_df\n",
    "\n",
    "def correlate_features(df):\n",
    "    cleaned_df = pycytominer.feature_select(\n",
    "        profiles=df,\n",
    "        operation=\"correlation_threshold\",\n",
    "        corr_threshold=0.99 # 0.99\n",
    "    )\n",
    "    num_removed = df.shape[1] - cleaned_df.shape[1]\n",
    "    print(f\"A total of {num_removed} correlated features are removed. {cleaned_df.shape[1]} features remaining\")\n",
    "    return cleaned_df\n",
    "\n",
    "def remove_outliers(df):\n",
    "    cleaned_df = pycytominer.feature_select(\n",
    "        profiles=df,\n",
    "        operation=\"drop_outliers\",\n",
    "        outlier_cutoff=100\n",
    "    )\n",
    "    num_removed = df.shape[1] - cleaned_df.shape[1]\n",
    "    print(f\"A total of {num_removed} outlier features are removed. {cleaned_df.shape[1]} features remaining\")\n",
    "    return cleaned_df\n",
    "\n",
    "def filter_variance(df):\n",
    "    cleaned_df = pycytominer.feature_select(\n",
    "        profiles=df,\n",
    "        operation=\"variance_threshold\",\n",
    "        samples=\"all\",\n",
    "        unique_cut=0.1\n",
    "    )\n",
    "    num_removed = df.shape[1] - cleaned_df.shape[1]\n",
    "    print(f\"A total of {num_removed} invariant features are detected. {cleaned_df.shape[1]} features remaining\")\n",
    "    return cleaned_df\n",
    "\n",
    "def remove_noisy_features(df):\n",
    "    cleaned_df = pycytominer.feature_select(\n",
    "        profiles=df,\n",
    "        operation=\"noise_removal\",\n",
    "        noise_removal_stdev_cutoff=3, #3\n",
    "        samples=\"all\",\n",
    "        noise_removal_perturb_groups=\"Metadata_cmpdName\"\n",
    "    )\n",
    "    num_removed = df.shape[1] - cleaned_df.shape[1]\n",
    "    print(f\"A total of {num_removed} noisy features are removed. {cleaned_df.shape[1]} features remaining\")\n",
    "    return cleaned_df\n",
    "\n",
    "def drop_na_columns(df):\n",
    "    cleaned_df = pycytominer.feature_select(\n",
    "        profiles=df,\n",
    "        na_cutoff=0,\n",
    "        operation=\"drop_na_columns\"\n",
    "    )\n",
    "    num_removed = df.shape[1] - cleaned_df.shape[1]\n",
    "    print(f\"A total of {num_removed} NAN features are removed. {cleaned_df.shape[1]} features remaining\")\n",
    "    return cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A total of 2122 features are detected\n",
      "A total of 55 features are removed from a total of 55 blocklisted features. 2067 features remaining\n",
      "A total of 280 correlated features are removed. 1787 features remaining\n",
      "A total of 276 outlier features are removed. 1511 features remaining\n",
      "A total of 308 invariant features are detected. 1203 features remaining\n",
      "A total of 0 noisy features are removed. 1203 features remaining\n",
      "A total of 9 NAN features are removed. 1194 features remaining\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_parquet('level5_AllPlates_mad_robustize_DMSO.parquet')\n",
    "print(\"A total of\", df.shape[1], \"features are detected\")\n",
    "    \n",
    "df = blocklist_features(df)\n",
    "df = correlate_features(df)\n",
    "df = remove_outliers(df)\n",
    "df = filter_variance(df)\n",
    "df = remove_noisy_features(df)\n",
    "df = drop_na_columns(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet(\"level6.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
